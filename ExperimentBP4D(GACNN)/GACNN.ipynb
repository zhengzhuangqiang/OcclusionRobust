{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:22.459277Z",
     "start_time": "2019-06-10T03:08:21.629579Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:22.520976Z",
     "start_time": "2019-06-10T03:08:22.461522Z"
    },
    "code_folding": [
     66
    ]
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, dataset_str, img_dir, occ_dir, occ_type):\n",
    "        \"\"\"\n",
    "            return: (img, landmarks), aus\n",
    "        \"\"\"\n",
    "        self.df, self.dataset_str, self.img_dir = df.copy(), dataset_str, img_dir\n",
    "        self.occ_dir,  self.occ_type = occ_dir, occ_type\n",
    "        \n",
    "        self.img_path = ['/'.join([img_dir, val]) for val in df['path']]\n",
    "        self.landmarks = df.values[:, -48:].reshape((-1,24,2)).astype(np.float32)/108*224\n",
    "        select_AU = [ 'AU01','AU02', 'AU04', 'AU06', 'AU07', 'AU10', \\\n",
    "                     'AU12', 'AU14', 'AU15', 'AU17','AU23', 'AU24']\n",
    "        self.aus = df[select_AU].values.astype(np.float32)\n",
    "        \n",
    "        def fun(x):\n",
    "            \"\"\" 单张图像标准化 \"\"\"\n",
    "            c, w, h = x.shape\n",
    "            x = x.view((c,-1))\n",
    "            x = (x-torch.mean(x, dim=1, keepdim=True))/(torch.std(x,dim=1, keepdim=True)+1e-5)\n",
    "            x = x.view((c,w,h))\n",
    "            return x\n",
    "        self.img_preprocess = transforms.Compose([\n",
    "            transforms.Resize([224, 224], interpolation=Image.CUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.44225878, 0.27311772, 0.21546765], \\\n",
    "                                 std=[0.25960645, 0.16986448, 0.13451453]),\n",
    "            #transforms.Lambda(lambd=fun),\n",
    "        ])\n",
    "        if dataset_str in ['train_mix', 'train_clean', 'train_occ']:\n",
    "            img_aug = transforms.Compose([\n",
    "                transforms.ColorJitter(\n",
    "                    brightness=0.4,\n",
    "                    saturation=0.4\n",
    "                ),\n",
    "                #transforms.RandomRotation(10),\n",
    "                #transforms.RandomHorizontalFlip()\n",
    "            ])\n",
    "            self.img_preprocess.transforms = img_aug.transforms+self.img_preprocess.transforms\n",
    "        \n",
    "        self.occ_img_preprocess = transforms.Compose([\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.RandomHorizontalFlip()\n",
    "        ])\n",
    "        self.occ_imgs = self.__get_occ_list()\n",
    "        \n",
    "    def __get_occ_list(self):\n",
    "        file_list = [np.array(Image.open('/'.join([self.occ_dir, val]))) for val in os.listdir(self.occ_dir)]\n",
    "        return file_list\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = Image.open(self.img_path[index]).convert(mode='RGB')\n",
    "        landmarks = self.landmarks[index]\n",
    "        aus = self.aus[index]\n",
    "        if self.dataset_str in ['train_mix', 'valid_mix']:\n",
    "            occlusion = np.random.randint(0, 2, (1,)).astype(np.int64)[0]\n",
    "        elif self.dataset_str in ['train_clean', 'valid_clean']:\n",
    "            occlusion = 0\n",
    "        elif self.dataset_str in ['train_occ', 'valid_occ']:\n",
    "            occlusion = 1\n",
    "        \n",
    "        if occlusion == 1: X = self.__addOcclusion(X)\n",
    "        \n",
    "        X = self.img_preprocess(X)\n",
    "        return (X, torch.tensor(landmarks)), aus\n",
    "    \n",
    "    def __addOcclusion(self, X):\n",
    "        short = min(X.size)\n",
    "        X = np.array(X)\n",
    "        # (row, col)随机选取\n",
    "        row = np.random.randint(X.shape[0]) \n",
    "        col = np.random.randint(X.shape[1])\n",
    "\n",
    "        if self.occ_type == 'one-sixth':\n",
    "            occ_size = short // 6\n",
    "        elif self.occ_type == 'one-third':\n",
    "            occ_size = short // 3\n",
    "        elif self.occ_type == 'one-second':\n",
    "            occ_size = short // 2\n",
    "\n",
    "        # 随机选择一幅遮挡素材\n",
    "        occ = self.occ_imgs[np.random.randint(0, len(self.occ_imgs))]\n",
    "        occ = Image.fromarray(occ).convert('RGBA')\n",
    "        #occ = Image.open(occ)\n",
    "        occ = self.occ_img_preprocess(occ)\n",
    "        occ = occ.resize((occ_size, occ_size))\n",
    "        occ = np.array(occ)\n",
    "        \n",
    "        # 在(row, col)处叠加遮挡素材\n",
    "        row_begin = row - occ_size // 2\n",
    "        col_begin = col - occ_size // 2\n",
    "        row_begin = 0 if row_begin < 0 else row_begin\n",
    "        col_begin = 0 if col_begin < 0 else col_begin\n",
    "        patch = X[row_begin : (row_begin + occ_size), col_begin : (col_begin + occ_size), :]\n",
    "        \n",
    "        # 裁剪mask使得occ，使得occ和patch的shape完全相同\n",
    "        occ = occ[:patch.shape[0], :patch.shape[1]]\n",
    "        mask = occ[:, :, 3] > 150 #遮挡图像的白色区域不融合\n",
    "        mask = np.expand_dims(mask, 2)\n",
    "        mask = np.tile(mask, [1, 1, 3])\n",
    "\n",
    "        temp = patch * (1 - mask) + occ[:, :, :3] * mask\n",
    "        X[row_begin : row_begin + occ_size, col_begin : col_begin + occ_size, :] = temp\n",
    "        X = Image.fromarray(X)\n",
    "        return X\n",
    "    \n",
    "    def __len__(self): return len(self.img_path)\n",
    "\n",
    "def compute_mean_std(ds):\n",
    "    ex1 = []\n",
    "    exs1 = []\n",
    "    for i in tqdm.tqdm_notebook(range(len(ds))):\n",
    "        x, y = ds[i]\n",
    "        img1 = x.numpy()\n",
    "        ex1.append(np.mean(img1, axis=(1,2)))\n",
    "        exs1.append(np.mean(img1*img1, axis=(1,2)))\n",
    "    ex1 = np.stack(ex1, axis=0).mean(axis=0)\n",
    "    exs1 = np.stack(exs1, axis=0).mean(axis=0)\n",
    "    s1 = np.sqrt(exs1-ex1*ex1)\n",
    "    print(\"mean1:\", ex1)\n",
    "    print(\"s1:\", s1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:22.531522Z",
     "start_time": "2019-06-10T03:08:22.522844Z"
    }
   },
   "outputs": [],
   "source": [
    "# img_dir = '../dataBP4D/Images'\n",
    "# occ_dir = '../Occlusion Resource'\n",
    "# df = pd.read_csv('../dataBP4D/label_withLandmarks.csv')\n",
    "# m = {}\n",
    "# for i, v in enumerate(df.subject.value_counts().index):\n",
    "#     m[v] = i\n",
    "# df.subject = df.subject.map(m)\n",
    "# ds = MyDataset(df, 'train_mix', img_dir, occ_dir, occ_type='one-second')\n",
    "# img, landmarks = ds[0][0]\n",
    "# plt.imshow(np.transpose(img, (1,2,0)))\n",
    "# plt.scatter(landmarks[:,1], landmarks[:,0])\n",
    "# for i in range(24):\n",
    "#     plt.text(landmarks[i,1], landmarks[i,0], str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:23.612419Z",
     "start_time": "2019-06-10T03:08:22.533800Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from fastai.vision import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:23.624328Z",
     "start_time": "2019-06-10T03:08:23.614572Z"
    }
   },
   "outputs": [],
   "source": [
    "class PGUnit(nn.Module):\n",
    "    def __init__(self, in_channels, size, num_out):\n",
    "        '''\n",
    "            input: bs x 512 x k x k\n",
    "            output: bs x num_out\n",
    "        '''\n",
    "        super(PGUnit, self).__init__()\n",
    "        self.body = nn.Sequential(*[\n",
    "            nn.Conv2d(in_channels, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512), nn.ReLU(inplace=True),\n",
    "        ])\n",
    "        self.attention = self.__make_attention_layers(512)\n",
    "        self.fc = nn.Sequential(*[\n",
    "            nn.Linear(512*size*size, num_out), nn.ReLU(inplace=True),\n",
    "        ])\n",
    "    def __make_attention_layers(self, num_features):\n",
    "        tmp = nn.Sequential(*[\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(num_features, out_channels=128, kernel_size=1, stride=1, padding=1), #为了改变通道数目\n",
    "            nn.BatchNorm2d(128),nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(output_size=[1,1]), Flatten(),\n",
    "            nn.Linear(128, 64),nn.BatchNorm1d(64),nn.ReLU(inplace=True),\n",
    "            nn.Linear(64,1),nn.BatchNorm1d(1, affine=True),nn.Sigmoid(), #caffe中scale为batchNorm中的后续层，pytorch中默认包含\n",
    "        ])\n",
    "        return tmp\n",
    "    def forward(self, x):\n",
    "        h = self.body(x)\n",
    "        attention = self.attention(h)\n",
    "        features = self.fc(h.view(h.shape[0], -1))\n",
    "        return features*attention # 相当于caffe的Scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:23.635592Z",
     "start_time": "2019-06-10T03:08:23.626468Z"
    }
   },
   "outputs": [],
   "source": [
    "class GACNN(nn.Module):\n",
    "    def __init__(self, num_AU):\n",
    "        super(GACNN, self).__init__()\n",
    "        self.vgg_features = models.vgg16_bn(pretrained=True).features # return bs x 512 x28 x28\n",
    "        for val in range(30, 44): del self.vgg_features._modules[str(val)]\n",
    "        self.extra_vgg = nn.Sequential(*[\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        ])\n",
    "        for i in range(24): self._modules['PG%02d' % i] = PGUnit(512, 6, 64)\n",
    "        self._modules['PGWhole'] = PGUnit(512, 14, 512)\n",
    "        self.classifier = nn.Sequential(*[\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64*24+512, 1024), nn.Dropout(0.5), nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_AU),\n",
    "        ])\n",
    "    def __make_patchs(self, vgg_map, center_landmarks):\n",
    "        center_landmarks = (center_landmarks/224*28).long()\n",
    "        upleft_landmarks = (center_landmarks-torch.tensor([[[3,3]]]).cuda()).long()\n",
    "        upleft_landmarks = torch.clamp(upleft_landmarks, min=0, max=22)\n",
    "        bs, channels = vgg_map.shape[:2]\n",
    "        out = torch.rand(24, bs, channels, 6, 6).cuda()\n",
    "        for i, one_sample in enumerate(upleft_landmarks):\n",
    "            for j, one_patch in enumerate(one_sample):\n",
    "                out[j][i] = vgg_map[i][:,one_patch[0]:one_patch[0]+6, one_patch[1]:one_patch[1]+6]\n",
    "        return out\n",
    "            \n",
    "    def forward(self, x):\n",
    "        img, landmarks = x\n",
    "        vgg_map = self.vgg_features(img)\n",
    "        vgg_patchs = self.__make_patchs(vgg_map, landmarks)\n",
    "        features = []\n",
    "        for i in range(24):\n",
    "            features.append(self._modules['PG%02d'%i](vgg_patchs[i]))\n",
    "        features.append(self._modules['PGWhole'](self.extra_vgg(vgg_map)))\n",
    "        features = torch.cat(features, dim=1)\n",
    "        \n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:23.651476Z",
     "start_time": "2019-06-10T03:08:23.637490Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision import SmoothenValue\n",
    "import sys\n",
    "stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:23.669004Z",
     "start_time": "2019-06-10T03:08:23.653929Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(dl, net, train_options, train_flag=False):\n",
    "    num_batchs = len(dl)\n",
    "    y_true, y_pred = [], []\n",
    "    avg_loss = SmoothenValue(beta=0.99)\n",
    "    if train_flag is True: net.train()\n",
    "    else: net.eval()\n",
    "    for i, (batch_Xs, batch_ys) in enumerate(dl):\n",
    "        batch_Xs = [val.cuda() for val in batch_Xs]\n",
    "        batch_ys = batch_ys.cuda()\n",
    "        \n",
    "        batch_ys_ = net(batch_Xs)\n",
    "        y_true.append(batch_ys.cpu().numpy())\n",
    "        y_pred.append(batch_ys_.detach().cpu().numpy())\n",
    "        cost = train_options['loss'](batch_ys_, batch_ys)\n",
    "        avg_loss.add_value(cost.item())\n",
    "        \n",
    "        if train_flag is True:\n",
    "            train_options['optimizer'].zero_grad()\n",
    "            cost.backward()\n",
    "            train_options['optimizer'].step()\n",
    "        \n",
    "        if train_options['show']!=-1 and i % train_options['show']==0:\n",
    "            stdout.write(\"%04d/%04d: loss-->%.6f\\n\" % (i, num_batchs, avg_loss.mov_avg))\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    return y_true, y_pred, avg_loss.mov_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:23.742173Z",
     "start_time": "2019-06-10T03:08:23.671714Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def evaluate_AU(y, y_, pivot=0.5):\n",
    "    y_ = (sigmoid(y_)>pivot).astype(np.int32)\n",
    "    f1 = f1_score(y_true=y, y_pred=y_, average='macro', pos_label=1)\n",
    "    all_f1 = f1_score(y_true=y, y_pred=y_, average=None, pos_label=1)\n",
    "    return {'f1': f1, 'all_f1':all_f1}\n",
    "\n",
    "def show(trn_metric, val_clean_metric, val_occ_metric):\n",
    "    ans = \"trn: \";\n",
    "    print(\"trn: \", end='\\n', file=log_file, flush=True)\n",
    "    for key, val in trn_metric.items():\n",
    "        if key!='all_f1':\n",
    "            ans = ans + \"(%s:%.4f)\"%(key,val)\n",
    "            print(\"(%s:%.4f)\"%(key,val), end='\\n', file=log_file, flush=True)\n",
    "        else:\n",
    "            print(val, end='\\n', file=log_file, flush=True)\n",
    "    ans = ans + \"\\t val_clean: \"\n",
    "    print(\"val_clean: \", end='\\n', file=log_file, flush=True)\n",
    "    for key, val in val_clean_metric.items():\n",
    "        if key!='all_f1':\n",
    "            ans = ans + \"(%s:%.4f)\"%(key,val)\n",
    "            print(\"(%s:%.4f)\"%(key,val), end='\\n', file=log_file, flush=True)\n",
    "        else:\n",
    "            print(val, end='\\n', file=log_file, flush=True)\n",
    "    ans = ans + \"\\t val_occ: \"\n",
    "    print(\"val_occ: \", end='\\n', file=log_file, flush=True)\n",
    "    for key, val in val_occ_metric.items():\n",
    "        if key!='all_f1':\n",
    "            ans = ans + \"(%s:%.4f)\"%(key,val)\n",
    "            print(\"(%s:%.4f)\"%(key,val), end='\\n', file=log_file, flush=True)\n",
    "        else:\n",
    "            print(val, end='\\n', file=log_file, flush=True)\n",
    "    return ans\n",
    "\n",
    "def f_train_process(dl, net, train_options, train_flag):\n",
    "    s = time.time()\n",
    "    y, y_, cost = train_one_epoch(dl, net, train_options, train_flag)\n",
    "    metric = evaluate_AU(y, y_)\n",
    "    print(\"elapsed %.4fs\" % (time.time()-s))\n",
    "    return metric\n",
    "def train_process(num_epochs, trn_dl, val_dl, net, train_options):\n",
    "    \n",
    "    best_eval = {'occ':0, 'clean':0}\n",
    "    for i in tqdm.tqdm_notebook(range(num_epochs)):\n",
    "        print((\"epochs %02d\" % i).center(50, '='), end='\\n', file=log_file, flush=True)\n",
    "        trn_metric = f_train_process(trn_dl, net, train_options, train_flag=True)\n",
    "        \n",
    "        val_dl.dataset.dataset_str = 'valid_clean'\n",
    "        val_clean_metric = f_train_process(valid_dl, net, train_options, train_flag=False)\n",
    "        val_dl.dataset.dataset_str = 'valid_occ'\n",
    "        val_occ_metric = f_train_process(valid_dl, net, train_options, train_flag=False)\n",
    "        \n",
    "        show_str = show(trn_metric, val_clean_metric, val_occ_metric)\n",
    "        tmp = \"Epoch: %03d \" % i\n",
    "        stdout.write(tmp+show_str+'\\n')\n",
    "        torch.save(net.state_dict(), f='/'.join([model_dir, train_options['time']+(\"Epoch%03d\"%i)]))\n",
    "    return best_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:23.762408Z",
     "start_time": "2019-06-10T03:08:23.744145Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:23.907220Z",
     "start_time": "2019-06-10T03:08:23.763839Z"
    }
   },
   "outputs": [],
   "source": [
    "img_dir = '../dataBP4D/Images'\n",
    "occ_dir = '../Occlusion Resource'\n",
    "df = pd.read_csv('../dataBP4D/label_withLandmarks.csv')\n",
    "m = {}\n",
    "for i, v in enumerate(df.subject.value_counts().index):\n",
    "    m[v] = i\n",
    "df.subject = df.subject.map(m)\n",
    "\n",
    "df_all = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AU recognition with mix training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:23.914452Z",
     "start_time": "2019-06-10T03:08:23.909691Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:24.187619Z",
     "start_time": "2019-06-10T03:08:23.930044Z"
    }
   },
   "outputs": [],
   "source": [
    "! rm ./log.txt\n",
    "! rm -r ./tmp/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:24.196236Z",
     "start_time": "2019-06-10T03:08:24.191408Z"
    }
   },
   "outputs": [],
   "source": [
    "log_file = open('./log.txt', 'a')\n",
    "print(time.asctime().center(100, '#'), end='\\n', file=log_file, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:24.206038Z",
     "start_time": "2019-06-10T03:08:24.198333Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dir = './tmp'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T03:08:31.261937Z",
     "start_time": "2019-06-10T03:08:24.208541Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=3, random_state=2019)\n",
    "subjects = df_all.subject.unique()\n",
    "for i, (train_index, valid_index) in enumerate(cv.split(range(len(subjects)))):\n",
    "    print((\"time%02d\"%i).center(100, '='), end='\\n', file=log_file, flush=True)\n",
    "    print((\"time%02d\"%i).center(100, '='), end='\\n', flush=True)\n",
    "    train_index, valid_index = subjects[train_index], subjects[valid_index]\n",
    "    train_df = df_all[df_all.subject.isin(values=train_index)]\n",
    "    valid_df = df_all[df_all.subject.isin(values=valid_index)]\n",
    "    train_ds = MyDataset(train_df, 'train_mix', img_dir, occ_dir, occ_type='one-second')\n",
    "    valid_ds = MyDataset(valid_df, 'valid_clean', img_dir, occ_dir, occ_type='one-second')\n",
    "    train_dl = DataLoader(train_ds, batch_size=16, num_workers=4, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=16, num_workers=4, shuffle=False)\n",
    "    \n",
    "    my_net = GACNN(num_AU=12).cuda()\n",
    "    train_options = {}\n",
    "    for val in my_net.vgg_features.parameters(): val.requires_grad = False\n",
    "    train_options['optimizer'] = optim.Adam(filter(lambda p: p.requires_grad, my_net.parameters()), lr=1e-4, weight_decay=1e-6)\n",
    "    train_options['loss'] = nn.BCEWithLogitsLoss().cuda()\n",
    "    train_options['show'] = 500\n",
    "    train_options['time'] = 'time%02d_'%i\n",
    "    cur_best_eval = train_process(10, train_dl, valid_dl, my_net, train_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.141px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
